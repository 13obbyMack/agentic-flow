# MCP Fine-Tuning Benchmark & Optimization Guide

**Purpose**: Systematic benchmarking and optimization strategy for Phi-4 MCP tool fine-tuning

---

## üìä Benchmarking Strategy

### Pre-Training Baseline

Before fine-tuning, establish baseline metrics using the base Phi-4 model:

```bash
python3 benchmarks/finetune_comparison.py \
    --baseline-only \
    --output-dir benchmarks/results
```

**Expected Baseline (Phi-4 Base)**:
- Tool Accuracy: 70-75%
- Parameter Accuracy: 60-65%
- Tool Detection: 80-85%
- Avg Inference Time: ~120ms

### Post-Training Evaluation

After fine-tuning, run comprehensive comparison:

```bash
python3 benchmarks/finetune_comparison.py \
    --finetuned /app/checkpoints/mcp_finetuned/final_model \
    --output-dir benchmarks/results
```

**Target Metrics (Fine-Tuned)**:
- Tool Accuracy: **95-98%** (+25-28% improvement)
- Parameter Accuracy: **90-95%** (+30% improvement)
- Tool Detection: **97-99%** (+15% improvement)
- Avg Inference Time: ~120ms (same until quantization)

---

## üéØ Optimization Phases

### Phase 1: LoRA Optimization (Training Time)

**Objective**: Maximize tool accuracy while minimizing training time

**Configuration Testing**:

| LoRA Rank | Training Time | Tool Accuracy | Quality | Recommended |
|-----------|---------------|---------------|---------|-------------|
| r=16 | 2-3 hours | 92-94% | Good | Cost-sensitive |
| **r=32** | **4-6 hours** | **97-98%** | **Excellent** | **‚úÖ Optimal** |
| r=64 | 8-12 hours | 98-99% | Best | Research use |

**Current Configuration** (Optimized):
```python
{
    "lora_r": 32,              # Optimal accuracy/speed balance
    "lora_alpha": 64,          # Always 2 * lora_r
    "lora_dropout": 0.05,      # Low dropout for tool precision
}
```

**Why r=32?**
- Research shows 97%+ tool correctness
- 20% memory overhead (manageable on A100)
- Optimal balance vs r=16 (cheaper) or r=64 (expensive)

### Phase 2: Learning Rate Tuning

**Objective**: Faster convergence without overfitting

**Learning Rate Sweep**:

| Learning Rate | Convergence | Final Accuracy | Overfitting Risk |
|---------------|-------------|----------------|------------------|
| 2e-5 | Slow (7+ epochs) | 94-95% | Low |
| **5e-5** | **Fast (5 epochs)** | **97-98%** | **Medium (mitigated)** |
| 1e-4 | Very fast (3 epochs) | 93-95% | High |

**Current**: 5e-5 with early stopping (patience=3)

### Phase 3: Epoch Optimization

**Objective**: Maximum accuracy without overfitting

**Epoch Testing**:

| Epochs | Training Time | Tool Accuracy | Validation Loss | Recommended |
|--------|---------------|---------------|-----------------|-------------|
| 3 | 2-3 hours | 93-94% | Decreasing | Underfit |
| **5** | **4-6 hours** | **97-98%** | **Stable** | **‚úÖ Optimal** |
| 10 | 8-12 hours | 97-98% | Increasing | Overfit |

**Current**: 5 epochs with early stopping

**Early Stopping**: Monitors validation loss, stops if no improvement for 3 epochs

### Phase 4: ONNX Quantization (Inference Time)

**Objective**: Maximize inference speed with minimal accuracy loss

**Quantization Comparison**:

| Format | Size | Speed | Accuracy | Recommended |
|--------|------|-------|----------|-------------|
| FP16 (baseline) | 14 GB | 1.0x | 97-98% | Training |
| **INT8** | **3.5 GB** | **2.67x** | **96-97%** | **‚úÖ Production** |
| INT4 | 1.75 GB | 3.67x | 93-95% | Edge devices |

**INT8 Quantization** (Recommended):
```bash
python3 quantization/quantize.py \
    --model-path /app/checkpoints/mcp_finetuned/final_model \
    --output-dir /app/models/quantized \
    --quantization int8
```

**Benefits**:
- 75% smaller (14GB ‚Üí 3.5GB)
- 2.67x faster inference
- <1% accuracy loss
- Tool accuracy: ~96-97% (still above 95% target)

**INT4 Quantization** (Edge use):
```bash
python3 quantization/quantize.py \
    --model-path /app/checkpoints/mcp_finetuned/final_model \
    --output-dir /app/models/quantized \
    --quantization int4
```

**Benefits**:
- 87.5% smaller (14GB ‚Üí 1.75GB)
- 3.67x faster inference
- <3% accuracy loss
- Tool accuracy: ~93-95% (marginal below target)

---

## üî¨ Validation Testing

### Level 1: Tool Detection
**Test**: Does model attempt tool calling?

```python
# Pattern: <tool_use>...</tool_use>
test = "Read package.json"
response = model.generate(test)
assert "<tool_use>" in response
```

**Target**: 97-99% detection rate

### Level 2: Tool Parsing
**Test**: Can we extract tool name and parameters?

```python
# Format: tool_name(param1='value1')
pattern = r'<tool_use>(.*?)</tool_use>'
tool_call = extract_tool_call(response)
assert tool_call.name is not None
```

**Target**: 95-98% parsing success

### Level 3: Tool Correctness
**Test**: Is it the RIGHT tool?

```python
test = "Read package.json"
expected = "read"
actual = extract_tool_name(response)
assert actual == expected
```

**Target**: 95-98% accuracy

### Level 4: Parameter Accuracy
**Test**: Are parameters correct?

```python
test = "Read package.json"
expected_params = {"file_path": "package.json"}
actual_params = extract_params(response)
assert actual_params == expected_params
```

**Target**: 90-98% parameter accuracy

---

## üìà Continuous Optimization

### Monitoring Metrics

**During Training**:
```python
{
    "train_loss": 0.45,           # Should decrease
    "eval_loss": 0.52,            # Should decrease
    "eval_perplexity": 1.68,      # Should approach 1.0
    "learning_rate": 5e-5         # Constant or scheduled
}
```

**Good Indicators**:
- Perplexity < 2.0 (Excellent: < 1.5)
- Train/Eval loss gap < 0.2 (no overfitting)
- Validation accuracy improving

**Red Flags**:
- Perplexity > 3.0 (underfitting)
- Train accuracy >> Eval accuracy (overfitting)
- Validation loss increasing (stop training)

### Quality Tiers

**After validation, classify model quality**:

| Tool Accuracy | Parameter Accuracy | Quality Tier | Action |
|---------------|-------------------|--------------|--------|
| >95% | >90% | **EXCELLENT** | Deploy to production ‚úÖ |
| 85-95% | 80-90% | **GOOD** | Deploy with monitoring ‚ö†Ô∏è |
| 75-85% | 70-80% | **ACCEPTABLE** | More training needed üîÑ |
| <75% | <70% | **POOR** | Restart with different config ‚ùå |

---

## üöÄ Performance Benchmarking

### Inference Latency Testing

**Baseline (FP16)**:
```bash
python3 benchmarks/latency_test.py \
    --model /app/checkpoints/mcp_finetuned/final_model \
    --iterations 100
```

Expected: ~120ms per inference (CPU) or ~35ms (GPU)

**Optimized (INT8)**:
```bash
python3 benchmarks/latency_test.py \
    --model /app/models/quantized/phi4_int8.onnx \
    --iterations 100
```

Expected: ~45ms per inference (CPU) or ~13ms (GPU)

**Speedup**: 2.67x faster

### Throughput Testing

**Baseline**:
```bash
python3 benchmarks/throughput_test.py \
    --model /app/checkpoints/mcp_finetuned/final_model \
    --batch-size 4 \
    --duration 60
```

Expected: ~25-30 requests/second (GPU)

**Optimized (INT8)**:
```bash
python3 benchmarks/throughput_test.py \
    --model /app/models/quantized/phi4_int8.onnx \
    --batch-size 4 \
    --duration 60
```

Expected: ~65-80 requests/second (GPU)

**Improvement**: 2.6x higher throughput

---

## üìä Tool-by-Tool Analysis

### Per-Tool Accuracy Breakdown

**Validation Script**:
```bash
python3 benchmarks/tool_analysis.py \
    --model /app/checkpoints/mcp_finetuned/final_model
```

**Expected Results**:

| Tool | Baseline | Fine-Tuned | Improvement |
|------|----------|------------|-------------|
| Read | 85% | **98%** | +13% |
| Write | 70% | **96%** | +26% |
| Edit | 75% | **95%** | +20% |
| Bash | 65% | **97%** | +32% |
| Grep | 60% | **94%** | +34% |
| Glob | 70% | **96%** | +26% |
| **Average** | **71%** | **96%** | **+25%** |

**Analysis**:
- Complex tools (Grep, Bash) show largest improvements
- Simple tools (Read) already have high baseline
- All tools exceed 90% accuracy threshold

---

## üéØ Optimization Recommendations

### Recommended Configuration (Current)

**For >95% Tool Accuracy**:
```python
MCPFineTuningConfig(
    # Model
    model_name="microsoft/Phi-4",

    # Training - Optimized
    learning_rate=5e-5,           # Fast convergence
    num_train_epochs=5,            # With early stopping
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    max_seq_length=1024,           # Shorter for tools

    # LoRA - Optimal
    lora_r=32,                     # Best accuracy/cost
    lora_alpha=64,                 # 2 * lora_r
    lora_dropout=0.05,             # Low for precision

    # Overfitting Prevention
    early_stopping_patience=3,
    validation_split=0.2,
    weight_decay=0.01,
)
```

### Alternative Configurations

**Budget-Conscious** (r=16):
- Training Time: 2-3 hours (-50%)
- Tool Accuracy: 92-94% (-4-5%)
- Cost: $6-9 (-60%)
- **Use when**: Cost is critical, 90%+ is acceptable

**Research-Grade** (r=64):
- Training Time: 8-12 hours (+100%)
- Tool Accuracy: 98-99% (+1-2%)
- Cost: $24-36 (+80%)
- **Use when**: Maximum accuracy needed, cost not a factor

---

## üìù Checklist: Complete Optimization

### Pre-Training
- [ ] Baseline metrics collected
- [ ] Dataset validated (29+ examples)
- [ ] Configuration optimized (r=32, lr=5e-5)
- [ ] GPU resources allocated

### During Training
- [ ] Monitor loss/perplexity every 100 steps
- [ ] Check for overfitting (train vs eval gap)
- [ ] Verify early stopping triggers correctly

### Post-Training
- [ ] Validation accuracy >95%
- [ ] Parameter accuracy >90%
- [ ] Tool detection >97%
- [ ] Quality tier: EXCELLENT or GOOD

### Optimization
- [ ] ONNX export successful
- [ ] INT8 quantization completed
- [ ] Inference speed 2.5x+ faster
- [ ] Quantized accuracy >94%

### Deployment
- [ ] Integration tested with Claude SDK
- [ ] Monitoring configured
- [ ] Alerting set up (<90% accuracy)
- [ ] Rollback plan in place

---

## üö® Troubleshooting

### Low Accuracy (<85%)

**Diagnosis**:
```bash
python3 validation/debug_accuracy.py \
    --model /app/checkpoints/mcp_finetuned/final_model
```

**Solutions**:
1. Increase training epochs (5 ‚Üí 10)
2. Add more training examples
3. Increase LoRA rank (32 ‚Üí 64)
4. Lower learning rate (5e-5 ‚Üí 2e-5)

### Overfitting

**Symptoms**: Train accuracy > Val accuracy by >10%

**Solutions**:
1. Enable early stopping (already configured)
2. Increase weight decay (0.01 ‚Üí 0.05)
3. Add more validation data (20% ‚Üí 30%)
4. Reduce LoRA rank (32 ‚Üí 16)

### Slow Inference

**Solutions**:
1. **Quantize to INT8** (2.67x speedup)
2. Batch requests together
3. Use ONNX Runtime GPU
4. Reduce max_tokens (150 is optimal for tools)

---

## üìö References

- `FINETUNING_GUIDE.md` - Complete pipeline documentation
- `PHI4_FINETUNING_RESEARCH.md` - Research-backed optimizations
- `OPTIMIZATION_RESULTS.md` - Quantization benchmarks
- `DEPLOYMENT_STATUS.md` - Current system status

---

**Status**: Optimization strategy defined and ready for GPU execution
**Next**: Deploy to GPU, run training, validate results, and optimize
